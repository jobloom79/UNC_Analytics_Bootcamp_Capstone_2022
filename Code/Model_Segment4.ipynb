{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Connecting to SQL Database and Loading data table in as dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-sql\n",
      "  Downloading ipython_sql-0.4.1-py3-none-any.whl (21 kB)\n",
      "Collecting prettytable<1\n",
      "  Downloading prettytable-0.7.2.zip (28 kB)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython-sql) (1.4.32)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: six in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython-sql) (7.31.1)\n",
      "Collecting sqlparse\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.16 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: pygments in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (2.11.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (3.0.20)\n",
      "Requirement already satisfied: decorator in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (61.2.0)\n",
      "Requirement already satisfied: appnope in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\n",
      "Requirement already satisfied: backcall in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from sqlalchemy>=0.6.7->ipython-sql) (4.11.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from sqlalchemy>=0.6.7->ipython-sql) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (4.1.1)\n",
      "Building wheels for collected packages: prettytable\n",
      "  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13714 sha256=5e58161bbf1d41b7a9027c34ff7820153d05107fb7a94379496a06ae9d9f26d4\n",
      "  Stored in directory: /Users/dang/Library/Caches/pip/wheels/b2/7f/f6/f180315b584f00445045ff1699b550fa895d09471337ce21c6\n",
      "Successfully built prettytable\n",
      "Installing collected packages: sqlparse, prettytable, ipython-sql\n",
      "Successfully installed ipython-sql-0.4.1 prettytable-0.7.2 sqlparse-0.4.3\n",
      "Requirement already satisfied: sqlalchemy in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (1.4.32)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from sqlalchemy) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dang/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing packages to use postgresql\n",
    "!pip install ipython-sql\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y4/n4l0qgqj4z51v6mn_zxclcmc0000gn/T/ipykernel_27772/4123529818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdb_password\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "# dependencies necessary for connecting to sql database\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = f\"postgresql://root:{db_password}@unc-capstone-db.chbhjul7q0jr.us-east-2.rds.amazonaws.com/cleaning_database_beta\"\n",
    "In [82]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://root:{db_password}@unc-capstone-db.chbhjul7q0jr.us-east-2.rds.amazonaws.com/cleaning_database_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT * FROM updated_animal_data1 LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sql data table into pandas dataframe\n",
    "animal_Data_df = pd.read_sql('SELECT * FROM updated_animal_data1', engine)\n",
    "animal_Data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking columns and data types\n",
    "animal_Data_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing data for supervised learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns that we do not need for model\n",
    "u1_animalData_df = animal_Data_df.drop(['animal_id', 'state', 'sex', 'animal_type', 'breed_class', 'color'], axis=1)\n",
    "print(u1_animalData_df.shape[0])\n",
    "u1_animalData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the `Not Tested` 4Dx status\n",
    "not_Tested_mask = u1_animalData_df['is_4dx_tested'] != 'Not Tested'\n",
    "tested_df = u1_animalData_df.loc[not_Tested_mask]\n",
    "\n",
    "print(tested_df.shape[0])\n",
    "print(tested_df.columns)\n",
    "tested_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values in the RR column - before converting to numerical\n",
    "tested_df['resp_rate_bpm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting RR column to integer\n",
    "tested_df['resp_rate_bpm'] = tested_df['resp_rate_bpm'].astype('int')\n",
    "\n",
    "tested_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the age column to just numbers - years\n",
    "# First, splitting the column into two new colummns - one for number and the other for the string (years, months, etc.)\n",
    "tested_df[['age_num', 'age_str']] = tested_df['age'].apply(lambda x: pd.Series(str(x).split(\" \")))\n",
    "\n",
    "# Setting the original age column equal to the age_num column - i.e. changing the data in the age column to just the numbers\n",
    "tested_df['age'] = tested_df['age_num']\n",
    "\n",
    "# Changing the data type of the age column to float\n",
    "tested_df['age'] = tested_df['age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Checking the column to see what the unique string values are\n",
    "tested_df[\"age_str\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the string column to change the number value - converting all ages to years\n",
    "tested_df.loc[tested_df.age_str == 'days', ['age']] = tested_df['age'] / 365\n",
    "tested_df.loc[tested_df.age_str == 'day', ['age']] = tested_df['age'] / 365\n",
    "tested_df.loc[tested_df.age_str == 'months', ['age']] = tested_df['age'] / 12\n",
    "tested_df.loc[tested_df.age_str == 'month', ['age']] = tested_df['age'] / 12\n",
    "tested_df.loc[tested_df.age_str == 'weeks', ['age']] = tested_df['age'] / 52\n",
    "tested_df.loc[tested_df.age_str == 'week', ['age']] = tested_df['age'] / 52\n",
    "\n",
    "print(tested_df.shape)\n",
    "tested_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the extra (created) columns - age_num and age_str\n",
    "final_animalData_df = tested_df.drop(['age_str', 'age_num'], axis=1)\n",
    "print(final_animalData_df.columns)\n",
    "print(final_animalData_df.dtypes)\n",
    "print(final_animalData_df.shape)\n",
    "final_animalData_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Defining our Target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features\n",
    "X = final_animalData_df.drop(columns='is_4dx_tested')\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Target\n",
    "y = final_animalData_df['is_4dx_tested']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of the target variable\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the data and Splitting our data into Training and Testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into testing and training sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Oversampling Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the data with the RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating an accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the confusion matrix\n",
    "Confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(Confusion_matrix, index=[\"Actual Negative\", \"Actual Positive\"], columns=[\"Predicted Negative\", \"Predicted Positive\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the classification report\n",
    "report_df = pd.DataFrame(classification_report_imbalanced(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE Oversampling Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data with SMOTE method\n",
    "X_resampled, y_resampled = SMOTE(random_state=42, sampling_strategy='auto').fit_resample(\n",
    "    X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the logistic regression model using the SMOTE resampled data\n",
    "model_SMOTE = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "model_SMOTE.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score\n",
    "y_pred = model_SMOTE.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the confusion matrix\n",
    "cm_SMOTE = confusion_matrix(y_test, y_pred)\n",
    "cm_df2 = pd.DataFrame(cm_SMOTE, index=[\"Actual Negative\", \"Actual Positive\"], columns=[\"Predicted Negative\", \"Predicted Positive\"])\n",
    "cm_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the classification table\n",
    "report_df2 = pd.DataFrame(classification_report_imbalanced(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uploading the updated table to SQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using label encoding to transform data in table that is better formatted for analysis in R\n",
    "# printing the classes for each variable to show what level will be assigned - the idex in the list is the level assigned to that descriptor\n",
    "og_final_animalData = final_animalData_df.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "final_animalData_df['mm'] = le.fit_transform(final_animalData_df['mm'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['crt'] = le.fit_transform(final_animalData_df['crt'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['mentation'] = le.fit_transform(final_animalData_df['mentation'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['diarrhea'] = le.fit_transform(final_animalData_df['diarrhea'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['vomiting'] = le.fit_transform(final_animalData_df['vomiting'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['inappetence'] = le.fit_transform(final_animalData_df['inappetence'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['lethargic'] = le.fit_transform(final_animalData_df['lethargic'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['muscle_pain'] = le.fit_transform(final_animalData_df['muscle_pain'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['lameness'] = le.fit_transform(final_animalData_df['lameness'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['reported_weight_loss'] = le.fit_transform(final_animalData_df['reported_weight_loss'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['joint_swelling'] = le.fit_transform(final_animalData_df['joint_swelling'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['skin_condition'] = le.fit_transform(final_animalData_df['skin_condition'])\n",
    "print(le.classes_)\n",
    "\n",
    "final_animalData_df['is_4dx_tested'] = le.fit_transform(final_animalData_df['is_4dx_tested'])\n",
    "print(le.classes_)\n",
    "\n",
    "\n",
    "# Adding code to write the cleaned dataframe to a new table in our PostgreSQL database\n",
    "final_animalData_df.to_sql(name='ml_cleaned_animalData', con=engine)\n",
    "\n",
    "final_animalData_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f48e098df2936069eb02f55b28918a3fc26e676acbb06ef38d904d73dc1646f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
